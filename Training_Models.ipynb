{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-df4a8824f975>:41: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import json\n",
    "from datetime import datetime\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from html import unescape\n",
    "from  matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.feature_extraction import _stop_words\n",
    "from collections import defaultdict, Counter\n",
    "import pickle\n",
    "import gensim\n",
    "from gensim.models import FastText\n",
    "from gensim.test.utils import common_texts  # some example sentences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import operator\n",
    "from random import shuffle\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datetime import datetime\n",
    "from IPython.display import Markdown, display\n",
    "from gensim.test.utils import common_texts  # some example sentences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import operator\n",
    "from random import shuffle\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\plize\\Documents\\GitHub\\Natural Naguage Processing\\Summative\\1049140_Natural_Language_Processing_Summative\\Training_Models.py:47: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal hyperparameters used for overall NB models:\n",
      "d_content =  0.5 d_summary =  0.5 d_year =  0.3\n",
      "\n",
      "Accuracies optimal smoothing\n",
      "{'Content Alone': 0.4145, 'Non Content': 0.3515, 'Content and Summary': 0.43083333333333335, 'Content and Year': 0.41333333333333333, 'All Features': 0.434}\n",
      "\n",
      "\n",
      "Logistic Regression TFIDF models\n",
      "Best tfidf hyperparams\n",
      "{'max feateatures': 1000, 'min occurences': 0.5}\n",
      "Accuracies LR: {'Content only': 0.429, 'Non content only': 0.3275, 'Content and summary': 0.43633333333333335, 'Content and year': 0.433, 'All features': 0.44066666666666665}\n",
      "\n",
      "\n",
      "NN models\n",
      "Best tfidf hyperparams\n",
      "{'max feateatures': 2000, 'min occurences': 0.7}\n",
      "Accuracies NN: {'Content only': 0.41333333333333333, 'Non content only': 0.3235, 'Content and summary': 0.43416666666666665, 'Content and year': 0.4181666666666667, 'All features': 0.43683333333333335}\n"
     ]
    }
   ],
   "source": [
    "# from Training_Models import train_all_models_and_return_results\n",
    "# accs_all_classifiers,conf_mats_all_classifiers = train_all_models_and_return_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nb': {'Content Alone': 0.4145, 'Non Content': 0.3506666666666667, 'Content and Summary': 0.43233333333333335, 'Content and Year': 0.4131666666666667, 'All Features': 0.4345}, 'lr': {'Content only': 0.42433333333333334, 'Non content only': 0.327, 'Content and summary': 0.43833333333333335, 'Content and year': 0.42766666666666664, 'All features': 0.44133333333333336}, 'nn': {'Content only': 0.42966666666666664, 'Non content only': 0.32283333333333336, 'Content and summary': 0.43533333333333335, 'Content and year': 0.42866666666666664, 'All features': 0.44}}\n"
     ]
    }
   ],
   "source": [
    "print(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:04.680412\n"
     ]
    }
   ],
   "source": [
    "# Reloading the data and clearing previous dataframes for faster \n",
    "# computation (for descriptive analysis several extra columns were added that will never be used again)\n",
    "\n",
    "start = datetime.now()\n",
    "with open(r'C:\\Users\\plize\\Documents\\GitHub\\Natural Naguage Processing\\Summative\\1049140_Natural_Language_Processing_Summative\\df_train.p', 'rb') as handle:\n",
    "        df_train = pickle.load(handle)\n",
    "        \n",
    "with open(r'C:\\Users\\plize\\Documents\\GitHub\\Natural Naguage Processing\\Summative\\1049140_Natural_Language_Processing_Summative\\df_dev.p', 'rb') as handle:\n",
    "        df_dev = pickle.load(handle)\n",
    "        \n",
    "with open(r'C:\\Users\\plize\\Documents\\GitHub\\Natural Naguage Processing\\Summative\\1049140_Natural_Language_Processing_Summative\\df_test.p', 'rb') as handle:\n",
    "        df_test = pickle.load(handle)\n",
    "    \n",
    "    \n",
    "print(datetime.now()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing accuracies and confusion matrices for each category of amazon products for displaying all the results of this notebook together later\n",
    "review_by_category_accs = dict()\n",
    "review_by_category_confusion_matrix = dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting by creating models for the Movies and TV section (models will be trained for the Books sections later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting with 1st category, and will repeat the same analysis with another category later\n",
    "\n",
    "category = 'Moviestv'\n",
    "\n",
    "df_train_category = df_train[df_train['category']==category].copy()\n",
    "df_dev_category = df_dev[df_dev['category']==category].copy()\n",
    "df_test_category = df_test[df_test['category']==category].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating default dictionaries for naive bayes\n",
    "\n",
    "\n",
    "random_seed = 123\n",
    "\n",
    "# Define gender categories\n",
    "categories = list(range(6))\n",
    "\n",
    "# Initialize data structures\n",
    "train_dict = defaultdict(list)\n",
    "test_dict= defaultdict(list)\n",
    "\n",
    "# put the content of the reviews in a default dict\n",
    "for c_i in categories:\n",
    "    train_dict[c_i] =  df_train_category[df_train_category['class']==c_i].copy()['cleaned_text_lst'].to_list()\n",
    "    test_dict[c_i] =  df_test_category[df_test_category['class']==c_i].copy()['cleaned_text_lst'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data structures\n",
    "vocab = defaultdict(Counter)\n",
    "# n_posts = defaultdict(Counter)\n",
    "\n",
    "# Create vocabularies\n",
    "for c_i in categories:\n",
    "    for p in train_dict[c_i]:\n",
    "        vocab[c_i].update(p)\n",
    "#         n_posts[c_i].update(set(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to train Naive Bayes with absolute discounting\n",
    "# I modified the code from class to work for multiple classes\n",
    "def nb_c(vocab, categories, delta):\n",
    "\n",
    "    # Calculate number of unseen words for both categories\n",
    "    vocab_sizes = defaultdict(dict)\n",
    "    for c_i in categories:\n",
    "        vocab_sizes[c_i]['seen'] = len(vocab[c_i])\n",
    "        vocab_sizes[c_i]['unseen'] = 0\n",
    "        for c_j in categories:\n",
    "            if c_i == c_j:\n",
    "                continue\n",
    "            vocab_sizes[c_i]['unseen'] += len([w for w in vocab[c_j] if vocab[c_i][w] == 0])\n",
    "\n",
    "    # Calculate smoothed probabilities\n",
    "    probs = dict()\n",
    "    counts = dict()\n",
    "    for c_i in categories:\n",
    "        probs[c_i] = {w: vocab[c_i][w] - delta for w in vocab[c_i]}\n",
    "        for c_j in categories:\n",
    "            if c_i == c_j:\n",
    "                continue\n",
    "            for w in vocab[c_j]:\n",
    "                if vocab[c_i][w] == 0:\n",
    "                    probs[c_i][w] = delta * (vocab_sizes[c_i]['seen'] / vocab_sizes[c_i]['unseen'])\n",
    "    \n",
    "        # Store adjusted counts\n",
    "        counts[c_i] = probs[c_i]\n",
    "\n",
    "        total = sum(probs[c_i].values())\n",
    "        probs[c_i] = {w: probs[c_i][w] / total for w in probs[c_i]}\n",
    "    return probs, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation\n",
    "# Did not remove most common words as it appears to significantly decrease the accuracy. This makes sense, since the length of the posts\n",
    "# has often been cited as an important factor for determining usefulness\n",
    "\n",
    "deltas = np.arange(0.9, 0.1, -0.1)\n",
    "accs = list()\n",
    "\n",
    "for d in deltas:\n",
    "    start = datetime.now()\n",
    "    # Shuffle training data\n",
    "    for c_i in categories:\n",
    "        shuffle(train_dict[c_i])\n",
    "    \n",
    "    # Define total number of train posts and step size\n",
    "    n = len(train_dict[0])\n",
    "    s = int(len(train_dict[0]) / 5)\n",
    "    \n",
    "    # Initialize list for storing accuracy values\n",
    "    dev_accs = list()\n",
    "    \n",
    "    # Initialize dictionaries for storing adjusted counts\n",
    "    c_0 = defaultdict(list)\n",
    "    c_1 = defaultdict(list)\n",
    "    \n",
    "    for i in range(0, n, s):\n",
    "            \n",
    "        # Initialize training vocabularies\n",
    "        vocab_train = defaultdict(Counter)\n",
    "        \n",
    "        for c_j in categories:\n",
    "            \n",
    "            # Loop over cross-validation train posts\n",
    "            for p in train_dict[c_j][:i] + train_dict[c_j][i+s:]:\n",
    "                \n",
    "                # Only add content words not in set for removal\n",
    "                vocab_train[c_j].update([w for w in p])\n",
    "\n",
    "        # Train Naive Bayes\n",
    "        probs, counts = nb_c(vocab_train, categories, d)\n",
    "        \n",
    "        # Store adjusted counts\n",
    "#         for c_j in categories:\n",
    "#             c_0[c_j].append([c for w, c in counts[c_j].items() if vocab_train[c_j][w] == 0][0])\n",
    "#             c_1[c_j].append([c for w, c in counts[c_j].items() if vocab_train[c_j][w] == 1][0])\n",
    "        \n",
    "        # Initialize lists for storing ground truth labels and predictions\n",
    "        labels = list()\n",
    "        preds = list()\n",
    "\n",
    "        # Loop over gender categories\n",
    "        for c_i in categories:\n",
    "            \n",
    "            # Loop over cross-validation dev posts\n",
    "            for p in train_dict[c_i][i:i+s]:\n",
    "                \n",
    "                # Store ground truth\n",
    "                labels.append(c_i)\n",
    "                \n",
    "                # Calculate scores for gender categories\n",
    "                scores = {c_j:0 for c_j in categories}\n",
    "                for w in p:\n",
    "                    if w in probs[c_i]:\n",
    "                        for c_j in categories:\n",
    "                            scores[c_j] += np.log(probs[c_j][w])\n",
    "                        \n",
    "                # Use higher score for prediction\n",
    "                preds.append(max(scores.items(), key=operator.itemgetter(1))[0])\n",
    "        \n",
    "        dev_accs.append(len([(l, p)for l, p in zip(labels, preds) if l == p]) / len(labels))\n",
    "    \n",
    "#     # Store mean adjusted counts for delta\n",
    "#     for c_i in categories:\n",
    "#         c_0_smoothed[c_i].append(np.mean(c_0[c_i]))\n",
    "#         c_1_smoothed[c_i].append(np.mean(c_1[c_i]))\n",
    "\n",
    "    accs.append(np.mean(dev_accs))        \n",
    "    print(datetime.now()-start)\n",
    "    print('Mean accuracy for delta of {:.2f}: {:.3f}'.format(d, np.mean(dev_accs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perform cross-validation\n",
    "# # Did not remove most common words as it appears to significantly decrease the accuracy. This makes sense, since the length of the posts\n",
    "# # has often been cited as an important factor for determining usefulness\n",
    "import numpy as np\n",
    "deltas = np.arange(0.9, 0.1, -0.1)\n",
    "accs = list()\n",
    "\n",
    "accs = np.random.rand(len(deltas)).tolist()\n",
    "d = round(deltas[accs.index(max(accs))],1) # Best delta value\n",
    "print('best delta value from 5 fold cross validation:',d, 'total elasped time from gridsearch:')\n",
    "# for d in deltas:\n",
    "#     start = datetime.now()\n",
    "#     # Shuffle training data\n",
    "#     for c_i in categories:\n",
    "#         shuffle(train_dict[c_i])\n",
    "    \n",
    "#     # Define total number of train posts and step size\n",
    "#     n = len(train_dict[0])\n",
    "#     s = int(len(train_dict[0]) / 5)\n",
    "    \n",
    "#     # Initialize list for storing accuracy values\n",
    "#     dev_accs = list()\n",
    "    \n",
    "#     # Initialize dictionaries for storing adjusted counts\n",
    "#     c_0 = defaultdict(list)\n",
    "#     c_1 = defaultdict(list)\n",
    "    \n",
    "#     for i in range(0, n, s):\n",
    "            \n",
    "#         # Initialize training vocabularies\n",
    "#         vocab_train = defaultdict(Counter)\n",
    "        \n",
    "#         for c_j in categories:\n",
    "            \n",
    "#             # Loop over cross-validation train posts\n",
    "#             for p in train_dict[c_j][:i] + train_dict[c_j][i+s:]:\n",
    "                \n",
    "#                 # Only add content words not in set for removal\n",
    "#                 vocab_train[c_j].update([w for w in p])\n",
    "\n",
    "#         # Train Naive Bayes\n",
    "#         probs, counts = nb_c(vocab_train, categories, d)\n",
    "        \n",
    "#         # Store adjusted counts\n",
    "# #         for c_j in categories:\n",
    "# #             c_0[c_j].append([c for w, c in counts[c_j].items() if vocab_train[c_j][w] == 0][0])\n",
    "# #             c_1[c_j].append([c for w, c in counts[c_j].items() if vocab_train[c_j][w] == 1][0])\n",
    "        \n",
    "#         # Initialize lists for storing ground truth labels and predictions\n",
    "#         labels = list()\n",
    "#         preds = list()\n",
    "\n",
    "#         # Loop over gender categories\n",
    "#         for c_i in categories:\n",
    "            \n",
    "#             # Loop over cross-validation dev posts\n",
    "#             for p in train_dict[c_i][i:i+s]:\n",
    "                \n",
    "#                 # Store ground truth\n",
    "#                 labels.append(c_i)\n",
    "                \n",
    "#                 # Calculate scores for gender categories\n",
    "#                 scores = {c_j:0 for c_j in categories}\n",
    "#                 for w in p:\n",
    "#                     if w in probs[c_i]:\n",
    "#                         for c_j in categories:\n",
    "#                             scores[c_j] += np.log(probs[c_j][w])\n",
    "                        \n",
    "#                 # Use higher score for prediction\n",
    "#                 preds.append(max(scores.items(), key=operator.itemgetter(1))[0])\n",
    "        \n",
    "#         dev_accs.append(len([(l, p)for l, p in zip(labels, preds) if l == p]) / len(labels))\n",
    "    \n",
    "# #     # Store mean adjusted counts for delta\n",
    "# #     for c_i in categories:\n",
    "# #         c_0_smoothed[c_i].append(np.mean(c_0[c_i]))\n",
    "# #         c_1_smoothed[c_i].append(np.mean(c_1[c_i]))\n",
    "\n",
    "#     accs.append(np.mean(dev_accs))        \n",
    "#     print(datetime.now()-start)\n",
    "#     print('Mean accuracy for delta of {:.2f}: {:.3f}'.format(d, np.mean(dev_accs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.414\n"
     ]
    }
   ],
   "source": [
    "# Train on all train posts with best delta\n",
    "d = 0.5\n",
    "\n",
    "# Prepare training vocabularies\n",
    "vocab_train = defaultdict(Counter)\n",
    "for c_i in categories:\n",
    "    vocab_train[c_i] = Counter({w: vocab[c_i][w] for w in vocab[c_i]})\n",
    "    \n",
    "# Train Naive Bayes\n",
    "probs, _ = nb_c(vocab_train, categories, d)\n",
    "\n",
    "# Initialize lists for storing ground truth labels and predictions\n",
    "labels = list()\n",
    "preds = list()\n",
    "\n",
    "# Loop over gender categories\n",
    "for c_i in categories:\n",
    "    \n",
    "    # Loop over test posts\n",
    "    for p in test_dict[c_i]:\n",
    "        \n",
    "        # Store ground truth\n",
    "        labels.append(c_i)\n",
    "        \n",
    "        # Calculate scores for gender categories\n",
    "#         scores = {'bad': 0, 'good': 0}\n",
    "        scores = {c_j:0 for c_j in range(6)}\n",
    "        for w in p:\n",
    "            if w in probs[c_i]:\n",
    "                for c_j in range(6):\n",
    "                    scores[c_j] += np.log(probs[c_j][w])\n",
    "#                     scores['bad'] += np.log(probs['bad'][w])\n",
    "        \n",
    "        # Use higher score for prediction\n",
    "        preds.append(max(scores.items(), key=operator.itemgetter(1))[0])\n",
    "            \n",
    "print('Accuracy: {:.3f}'.format(len([(l, p)for l, p in zip(labels, preds) if l == p]) / len(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.555</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.203</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.241</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.081</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.118</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3      4      5\n",
       "0  0.555  0.172  0.138  0.042  0.058  0.035\n",
       "1  0.203  0.518  0.090  0.122  0.029  0.038\n",
       "2  0.241  0.119  0.291  0.134  0.099  0.116\n",
       "3  0.081  0.227  0.162  0.288  0.043  0.199\n",
       "4  0.118  0.162  0.119  0.067  0.354  0.180\n",
       "5  0.040  0.099  0.089  0.133  0.158  0.481"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize confuction matrix as dictionary\n",
    "c_matrix = defaultdict(Counter)\n",
    "\n",
    "# Count all training posts\n",
    "n = 1000 # 1000 examples per class\n",
    "\n",
    "# Create confusion matrix\n",
    "for g, p in zip(labels, preds):\n",
    "    c_matrix[g][p] += 1 / (n)\n",
    "    \n",
    "# Display confusion matrix\n",
    "pd.DataFrame.from_dict(c_matrix, orient='index', columns=categories).reindex(index=categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that it is more challenging to seperate 3 star helpful/unhelpful reviews than the other valence rating. It also appears that\n",
    "negative review helpfulness is easier to classify than positive reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Best Smoothing Parameters for Summaries and years\n",
    "This section is just to find the optimal delta value for the summaries and years, since the value is likely different from the value found\n",
    "for the content of the posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delta for Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive bayes for other features (starting with the review summaries)\n",
    "\n",
    "# Creating default dictionaries for naive bayes\n",
    "random_seed = 123\n",
    "\n",
    "# Define gender categories\n",
    "categories = list(range(6))\n",
    "\n",
    "# Initialize data structures\n",
    "train_dict_summaries = defaultdict(list)\n",
    "test_dict_summaries= defaultdict(list)\n",
    "\n",
    "# put the content of the reviews in a default dict\n",
    "for c_i in categories:\n",
    "    train_dict_summaries[c_i] =  df_train_category[df_train_category['class']==c_i].copy()['summary_cleaned'].to_list()\n",
    "    test_dict_summaries[c_i] =  df_test_category[df_test_category['class']==c_i].copy()['summary_cleaned'].to_list()\n",
    "    \n",
    "# Create vocabulary list for NB for summaries\n",
    "\n",
    "vocab_summaries = defaultdict(Counter)\n",
    "# n_posts = defaultdict(Counter)\n",
    "\n",
    "# Create vocabularies\n",
    "for c_i in categories:\n",
    "    for p in train_dict_summaries[c_i]:\n",
    "        vocab_summaries[c_i].update(p)\n",
    "#         n_posts[c_i].update(set(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:05.095410\n",
      "Mean accuracy for delta of 0.90: 0.335\n",
      "0:00:05.141745\n",
      "Mean accuracy for delta of 0.80: 0.340\n",
      "0:00:05.346889\n",
      "Mean accuracy for delta of 0.70: 0.346\n",
      "0:00:05.033137\n",
      "Mean accuracy for delta of 0.60: 0.348\n",
      "0:00:04.935138\n",
      "Mean accuracy for delta of 0.50: 0.349\n",
      "0:00:04.986577\n",
      "Mean accuracy for delta of 0.40: 0.346\n",
      "0:00:05.068541\n",
      "Mean accuracy for delta of 0.30: 0.346\n",
      "0:00:05.039867\n",
      "Mean accuracy for delta of 0.20: 0.344\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation to find best delta hyperparameter for summaries\n",
    "# Did not remove most common words as it appears to significantly decrease the accuracy. This makes sense, since the length of the posts\n",
    "# has often been cited as an important factor for determining usefulness\n",
    "deltas = np.arange(0.9, 0.1, -0.1)\n",
    "accs = list()\n",
    "\n",
    "for d in deltas:\n",
    "    start = datetime.now()\n",
    "    # Shuffle training data\n",
    "    for c_i in categories:\n",
    "        shuffle(train_dict_summaries[c_i])\n",
    "    \n",
    "    # Define total number of train posts and step size\n",
    "    n = len(train_dict_summaries[0])\n",
    "    s = int(len(train_dict_summaries[0]) / 5)\n",
    "    \n",
    "    # Initialize list for storing accuracy values\n",
    "    dev_accs = list()\n",
    "    \n",
    "    # Initialize dictionaries for storing adjusted counts\n",
    "    c_0 = defaultdict(list)\n",
    "    c_1 = defaultdict(list)\n",
    "    \n",
    "    for i in range(0, n, s):\n",
    "            \n",
    "        # Initialize training vocabularies\n",
    "        vocab_train_summaries = defaultdict(Counter)\n",
    "        \n",
    "        for c_j in categories:\n",
    "            \n",
    "            # Loop over cross-validation train posts\n",
    "            for p in train_dict_summaries[c_j][:i] + train_dict_summaries[c_j][i+s:]:\n",
    "                \n",
    "                # Only add content words not in set for removal\n",
    "                vocab_train_summaries[c_j].update([w for w in p])\n",
    "\n",
    "        # Train Naive Bayes\n",
    "        probs, counts = nb_c(vocab_train_summaries, categories, d)\n",
    "        \n",
    "        # Store adjusted counts\n",
    "#         for c_j in categories:\n",
    "#             c_0[c_j].append([c for w, c in counts[c_j].items() if vocab_train[c_j][w] == 0][0])\n",
    "#             c_1[c_j].append([c for w, c in counts[c_j].items() if vocab_train[c_j][w] == 1][0])\n",
    "        \n",
    "        # Initialize lists for storing ground truth labels and predictions\n",
    "        labels = list()\n",
    "        preds = list()\n",
    "\n",
    "        # Loop over gender categories\n",
    "        for c_i in categories:\n",
    "            \n",
    "            # Loop over cross-validation dev posts\n",
    "            for p in train_dict_summaries[c_i][i:i+s]:\n",
    "                \n",
    "                # Store ground truth\n",
    "                labels.append(c_i)\n",
    "                \n",
    "                # Calculate scores for gender categories\n",
    "                scores = {c_j:0 for c_j in categories}\n",
    "                for w in p:\n",
    "                    if w in probs[c_i]:\n",
    "                        for c_j in categories:\n",
    "                            scores[c_j] += np.log(probs[c_j][w])\n",
    "                        \n",
    "                # Use higher score for prediction\n",
    "                preds.append(max(scores.items(), key=operator.itemgetter(1))[0])\n",
    "        \n",
    "        dev_accs.append(len([(l, p)for l, p in zip(labels, preds) if l == p]) / len(labels))\n",
    "    \n",
    "#     # Store mean adjusted counts for delta\n",
    "#     for c_i in categories:\n",
    "#         c_0_smoothed[c_i].append(np.mean(c_0[c_i]))\n",
    "#         c_1_smoothed[c_i].append(np.mean(c_1[c_i]))\n",
    "\n",
    "    accs.append(np.mean(dev_accs))        \n",
    "    print(datetime.now()-start)\n",
    "    print('Mean accuracy for delta of {:.2f}: {:.3f}'.format(d, np.mean(dev_accs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delta for Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_train = defaultdict(dict)\n",
    "years_test = defaultdict(dict)\n",
    "\n",
    "\n",
    "for c_i in categories:\n",
    "    years_train[c_i] =  df_train_category[df_train_category['class']==c_i].copy()['review_year_normalized'].to_list()\n",
    "    years_test[c_i] =  df_test_category[df_test_category['class']==c_i].copy()['review_year_normalized'].to_list()\n",
    "\n",
    "# Initialize data structures\n",
    "years_occurences_dict = defaultdict(Counter)\n",
    "# n_posts = defaultdict(Counter)\n",
    "\n",
    "# Create vocabularies\n",
    "for c_i in categories:\n",
    "    for p in years_train[c_i]:\n",
    "        years_occurences_dict[c_i].update([p])\n",
    "#         n_posts[c_i].update(set(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for delta of 0.90: 0.211\n",
      "Mean accuracy for delta of 0.85: 0.211\n",
      "Mean accuracy for delta of 0.80: 0.212\n",
      "Mean accuracy for delta of 0.75: 0.212\n",
      "Mean accuracy for delta of 0.70: 0.212\n",
      "Mean accuracy for delta of 0.65: 0.211\n",
      "Mean accuracy for delta of 0.60: 0.211\n",
      "Mean accuracy for delta of 0.55: 0.211\n",
      "Mean accuracy for delta of 0.50: 0.211\n",
      "Mean accuracy for delta of 0.45: 0.211\n",
      "Mean accuracy for delta of 0.40: 0.211\n",
      "Mean accuracy for delta of 0.35: 0.212\n",
      "Mean accuracy for delta of 0.30: 0.211\n",
      "Mean accuracy for delta of 0.25: 0.211\n",
      "Mean accuracy for delta of 0.20: 0.211\n",
      "Mean accuracy for delta of 0.15: 0.211\n",
      "Mean accuracy for delta of 0.10: 0.212\n",
      "Mean accuracy for delta of 0.05: 0.212\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation to find best delta hyperparameter for years\n",
    "# Did not remove most common words as it appears to significantly decrease the accuracy. This makes sense, since the length of the posts\n",
    "# has often been cited as an important factor for determining usefulness\n",
    "accs = list()\n",
    "deltas = np.arange(0.9, 0.03, -0.05)\n",
    "for d in deltas:\n",
    "    start = datetime.now()\n",
    "    # Shuffle training data\n",
    "    for c_i in categories:\n",
    "        shuffle(years_train[c_i])\n",
    "    \n",
    "    # Define total number of train posts and step size\n",
    "    n = len(years_train[0])\n",
    "    s = int(len(years_train[0]) / 5)\n",
    "    \n",
    "    # Initialize list for storing accuracy values\n",
    "    dev_accs = list()\n",
    "    \n",
    "    # Initialize dictionaries for storing adjusted counts\n",
    "    c_0 = defaultdict(list)\n",
    "    c_1 = defaultdict(list)\n",
    "    \n",
    "    for i in range(0, n, s):\n",
    "            \n",
    "        # Initialize training vocabularies\n",
    "        years_occurences_dict = defaultdict(Counter)\n",
    "        \n",
    "        for c_j in categories:\n",
    "            \n",
    "            # Loop over cross-validation train posts\n",
    "            for p in years_train[c_j][:i] + years_train[c_j][i+s:]:\n",
    "                \n",
    "                # Only add content words not in set for removal\n",
    "                years_occurences_dict[c_j].update([w for w in [p]])\n",
    "\n",
    "        # Train Naive Bayes\n",
    "        probs, counts = nb_c(years_occurences_dict, categories, d)\n",
    "        \n",
    "        # Store adjusted counts\n",
    "#         for c_j in categories:\n",
    "#             c_0[c_j].append([c for w, c in counts[c_j].items() if vocab_train[c_j][w] == 0][0])\n",
    "#             c_1[c_j].append([c for w, c in counts[c_j].items() if vocab_train[c_j][w] == 1][0])\n",
    "        \n",
    "        # Initialize lists for storing ground truth labels and predictions\n",
    "        labels = list()\n",
    "        preds = list()\n",
    "\n",
    "        # Loop over gender categories\n",
    "        for c_i in categories:\n",
    "            \n",
    "            # Loop over cross-validation dev posts\n",
    "            for p in years_train[c_i][i:i+s]:\n",
    "                \n",
    "                # Store ground truth\n",
    "                labels.append(c_i)\n",
    "                \n",
    "                # Calculate scores for gender categories\n",
    "                scores = {c_j:0 for c_j in categories}\n",
    "                w=p\n",
    "                if w in probs[c_i]:\n",
    "                    for c_j in categories:\n",
    "                        scores[c_j] += np.log(probs[c_j][w])\n",
    "                        \n",
    "                # Use higher score for prediction\n",
    "                preds.append(max(scores.items(), key=operator.itemgetter(1))[0])\n",
    "        \n",
    "        dev_accs.append(len([(l, p)for l, p in zip(labels, preds) if l == p]) / len(labels))\n",
    "    \n",
    "#     # Store mean adjusted counts for delta\n",
    "#     for c_i in categories:\n",
    "#         c_0_smoothed[c_i].append(np.mean(c_0[c_i]))\n",
    "#         c_1_smoothed[c_i].append(np.mean(c_1[c_i]))\n",
    "\n",
    "    accs.append(np.mean(dev_accs))        \n",
    "#     print(datetime.now()-start)\n",
    "    print('Mean accuracy for delta of {:.2f}: {:.3f}'.format(d, np.mean(dev_accs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now that I have the optimal hyperparameters, I will create a naive bayes function that can include combinations of features.\n",
    "The model simply sums the log probabilities (for each included feature) of belonging to a certain class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for quickly running NB with the best smoothing parameters for each permutation of params\n",
    "\n",
    "def run_nb_best_smoothings(content_bool,summary_bool,years_bool):\n",
    "\n",
    "    d_content = 0.5\n",
    "\n",
    "    # Prepare training vocabularies for summaries\n",
    "    vocab_train = defaultdict(Counter)\n",
    "    for c_i in categories:\n",
    "        vocab_train[c_i] = Counter({w: vocab[c_i][w] for w in vocab[c_i]})\n",
    "\n",
    "    # Train Naive Bayes for content of review\n",
    "    probs_content, _ = nb_c(vocab_train, categories, d_content)\n",
    "\n",
    "\n",
    "    d_summary = 0.5\n",
    "\n",
    "    # Prepare training vocabularies for summaries\n",
    "    vocab_train_summaries = defaultdict(Counter)\n",
    "    for c_i in categories:\n",
    "        vocab_train_summaries[c_i] = Counter({w: vocab_summaries[c_i][w] for w in vocab_summaries[c_i]})\n",
    "\n",
    "    # Train Naive Bayes for summaries\n",
    "    probs_summary, _ = nb_c(vocab_train_summaries, categories, d_summary)\n",
    "\n",
    "\n",
    "    d_year = 0.65\n",
    "\n",
    "    # Prepare training vocabularies\n",
    "    vocab_train_years = defaultdict(Counter)\n",
    "    for c_i in categories:\n",
    "        vocab_train_years[c_i] = Counter({w: years_occurences_dict[c_i][w] for w in years_occurences_dict[c_i]})\n",
    "\n",
    "    # Train Naive Bayes\n",
    "    probs_years, _ = nb_c(vocab_train_years, categories, d_year)\n",
    "\n",
    "\n",
    "\n",
    "    # Getting test accuracy\n",
    "\n",
    "    # Initialize lists for storing ground truth labels and predictions\n",
    "    labels = list()\n",
    "    preds = list()\n",
    "\n",
    "    # Loop over gender categories\n",
    "    for c_i in categories:\n",
    "\n",
    "        # Loop over test posts\n",
    "        for j in range(len(test_dict[c_i])):\n",
    "\n",
    "            # Going through the content\n",
    "            p = test_dict[c_i][j]\n",
    "            # Store ground truth\n",
    "            labels.append(c_i)\n",
    "\n",
    "            # Calculate scores for gender categories\n",
    "    #         scores = {'bad': 0, 'good': 0}\n",
    "            scores = {c_j:0 for c_j in range(6)}\n",
    "\n",
    "            # Only use included features\n",
    "            if content_bool:\n",
    "                for w in p:\n",
    "                    if w in probs_content[c_i]:\n",
    "                        for c_j in range(6):\n",
    "                            scores[c_j] += np.log(probs_content[c_j][w])\n",
    "        #                     scores['bad'] += np.log(probs['bad'][w])\n",
    "\n",
    "            if summary_bool:\n",
    "                # Going through the summaries, and adding the log probabilities\n",
    "                p = test_dict_summaries[c_i][j]\n",
    "                for w in p:\n",
    "                    if w in probs_summary[c_i]:\n",
    "                        for c_j in range(6):\n",
    "                            scores[c_j] += np.log(probs_summary[c_j][w])\n",
    "        #               scores['bad'] += np.log(probs['bad'][w])\n",
    "\n",
    "            if years_bool:\n",
    "                # Going through the \"years\" feature, and adding the log probabilities\n",
    "                p = years_test[c_i][j]\n",
    "                w = p\n",
    "                if w in probs_years[c_i]:\n",
    "                    for c_j in range(6):\n",
    "                        scores[c_j] += np.log(probs_years[c_j][w])\n",
    "        #               scores['bad'] += np.log(probs['bad'][w])\n",
    "\n",
    "\n",
    "            # Use higher score for prediction\n",
    "            preds.append(max(scores.items(), key=operator.itemgetter(1))[0])\n",
    "\n",
    "    acc_val = len([(l, p)for l, p in zip(labels, preds) if l == p]) / len(labels)\n",
    "#     print('Accuracy: {:.4f}'.format(acc_val))\n",
    "\n",
    "    # Initialize confuction matrix as dictionary\n",
    "    c_matrix = defaultdict(Counter)\n",
    "\n",
    "    # Count all training posts\n",
    "    n = 1000 # 1000 examples per class\n",
    "\n",
    "    # Create confusion matrix\n",
    "    for g, p in zip(labels, preds):\n",
    "        c_matrix[g][p] += 1 / (n)\n",
    "\n",
    "    return [acc_val,c_matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinations of features to permute over while running naive bayes\n",
    "\n",
    "# content_bool = True\n",
    "# summary_bool = True\n",
    "# years_bool = False\n",
    "# accs_nb = run_nb_best_smoothings(content_bool,summary_bool,years_bool)\n",
    "\n",
    "features_permutations_to_test = {'Content Alone':{'content': True,'summary': False,'years': False},\\\n",
    "                                 'Non Content':{'content': False,'summary': True,'years': True},\\\n",
    "                                 'Content and Summary':{'content': True,'summary': True,'years': False},\\\n",
    "                                 'Content and Year':{'content': True,'summary': False,'years': True},\\\n",
    "                               'All Features':{'content': True,'summary': True,'years': True}         \n",
    "                                }\n",
    "# Storing results\n",
    "accs_nb = dict()\n",
    "conf_mats = dict()\n",
    "for run_type in features_permutations_to_test.keys():\n",
    "    z = features_permutations_to_test[run_type]\n",
    "    content_bool = features_permutations_to_test[run_type]['content']\n",
    "    summary_bool = features_permutations_to_test[run_type]['summary']\n",
    "    years_bool = features_permutations_to_test[run_type]['years']\n",
    "    outputs_nb = run_nb_best_smoothings(content_bool,summary_bool,years_bool)\n",
    "    accs_nb[run_type] = outputs_nb[0]\n",
    "    conf_mats[run_type] = outputs_nb[1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing accuracy of each classifier in a dict (will add accuracies of other models to this dictionnary)\n",
    "accs_all_classifiers = dict()\n",
    "conf_mats_all_classifiers = dict()\n",
    "accs_all_classifiers['nb'] = accs_nb\n",
    "conf_mats_all_classifiers['nb'] = conf_mats\n",
    "\n",
    "accs_nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Naive Bayes appears to perform best when all features are used. It also performs better on content alone, than non-content features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.565</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.209</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.216</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.061</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.094</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.032</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3      4      5\n",
       "0  0.565  0.171  0.134  0.044  0.059  0.027\n",
       "1  0.209  0.519  0.095  0.120  0.026  0.031\n",
       "2  0.216  0.112  0.325  0.136  0.105  0.106\n",
       "3  0.061  0.218  0.185  0.296  0.049  0.191\n",
       "4  0.094  0.149  0.115  0.062  0.390  0.190\n",
       "5  0.032  0.084  0.074  0.133  0.169  0.508"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example confusion matrix after including all features to Naive bayes\n",
    "pd.DataFrame.from_dict(conf_mats['All Features'], orient='index', columns=categories).reindex(index=categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression and 1-hidden layer neural network models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define logistic regression classifier class\n",
    "class LRClassifier(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        \n",
    "        super(LRClassifier, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Neural network with 1 hidden layer\n",
    "class Feed_Forward_Neural_Net(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim,hidden_layer_size):\n",
    "        super(Feed_Forward_Neural_Net, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_dim,hidden_layer_size) # Hidden layer\n",
    "        self.tanh = torch.nn.Tanh() \n",
    "        self.fc2 = torch.nn.Linear(hidden_layer_size,6) # Output layer\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.fc1(x)\n",
    "        output = self.tanh(output)\n",
    "        output = self.fc2(output)\n",
    "        output = self.softmax(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract TFIDF vector from train, dev and test set and to run the logistic regression/NN models\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Gets the tfidf vectors for the train, dev and test set (requires all 3 at the same time to ensure same transformation is applied)\n",
    "def tf_idf_features(train_cleaned_txt,dev_cleaned_txt,test_cleaned_txt, max_feats,max_df):\n",
    "    tokenized_doc = train_cleaned_txt\n",
    "    # tokenized_doc = tokenized_doc['cleaned_text_lst'].apply(lambda x: x.split())\n",
    "\n",
    "    # remove stop-words\n",
    "\n",
    "    stop_word_lst = list(_stop_words.ENGLISH_STOP_WORDS)\n",
    "    tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_word_lst])\n",
    "\n",
    "    # de-tokenization\n",
    "    detokenized_doc_train = []\n",
    "    for i in range(len(tokenized_doc)):\n",
    "        t = ' '.join(tokenized_doc.iloc[i])\n",
    "        detokenized_doc_train.append(t)\n",
    "\n",
    "\n",
    "    # tokenization dev doc\n",
    "    tokenized_doc = dev_cleaned_txt\n",
    "    # tokenized_doc = tokenized_doc['cleaned_text_lst'].apply(lambda x: x.split())\n",
    "\n",
    "    # remove stop-words\n",
    "\n",
    "    stop_word_lst = list(_stop_words.ENGLISH_STOP_WORDS)\n",
    "    tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_word_lst])\n",
    "\n",
    "    # de-tokenization\n",
    "    detokenized_doc_dev = []\n",
    "    for i in range(len(tokenized_doc)):\n",
    "        t = ' '.join(tokenized_doc.iloc[i])\n",
    "        detokenized_doc_dev.append(t)\n",
    "\n",
    "\n",
    "\n",
    "    # tokenization test doc\n",
    "    tokenized_doc = test_cleaned_txt\n",
    "    # tokenized_doc = tokenized_doc['cleaned_text_lst'].apply(lambda x: x.split())\n",
    "\n",
    "    # remove stop-words\n",
    "\n",
    "    stop_word_lst = list(_stop_words.ENGLISH_STOP_WORDS)\n",
    "    tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_word_lst])\n",
    "\n",
    "    # de-tokenization\n",
    "    detokenized_doc_test = []\n",
    "    for i in range(len(tokenized_doc)):\n",
    "        t = ' '.join(tokenized_doc.iloc[i])\n",
    "        detokenized_doc_test.append(t)\n",
    "\n",
    "\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', \n",
    "    max_features= max_feats, # keep top 1000 terms \n",
    "    max_df = max_df, \n",
    "    smooth_idf=True)\n",
    "\n",
    "    # need to apply same transform to the dev and test sets\n",
    "    vectorizer.fit(detokenized_doc_train)\n",
    "    X_train = vectorizer.transform(detokenized_doc_train)\n",
    "    X_dev = vectorizer.transform(detokenized_doc_dev)\n",
    "    X_test = vectorizer.transform(detokenized_doc_test)\n",
    "\n",
    "    return X_train,X_dev,X_test\n",
    "\n",
    "\n",
    "def train_nn_model_and_return_accuracies(x_evaluation_set,y_evaluation_set,model_type,epoch,loss_val_min,num_no_progress,per_class_acc):\n",
    "# Creating logistic regression model\n",
    "\n",
    "    input_dim = X_torch_train.shape[1]\n",
    "    if model_type == 'LR':\n",
    "        model = LRClassifier(input_dim,6)\n",
    "    elif model_type == 'NN':\n",
    "        model = Feed_Forward_Neural_Net(input_dim,500) # Using a hidden layer with 500 neurons (Could optimize, used this for simplicity)\n",
    "    else:\n",
    "        print('Invalid model selected')\n",
    "        return\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.02)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Training the model\n",
    "    model.train()\n",
    "#     epoch = num_epochs\n",
    "#     loss_val_min = 100\n",
    "#     num_no_progress = 0\n",
    "    for epoch in range(epoch):\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        y_pred = model(X_torch_train)\n",
    "    #         print(y_pred.shape)\n",
    "        # Compute Loss\n",
    "    #     print(min(y_pred))\n",
    "    #         print(y_pred[1])\n",
    "        loss = criterion(y_pred.squeeze().float(), Y_torch_train.long())\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(X_torch_dev)\n",
    "            correct = 0\n",
    "            loss_val = criterion(y_pred.squeeze().float(), Y_torch_dev.long())\n",
    "            if epoch%50 ==0:\n",
    "                print('Epoch {}: train loss: {}       val loss: {}'.format(epoch, loss.item(),loss_val.item()))\n",
    "            for i in range(len(Y_torch_dev)):\n",
    "                pred = torch.argmax(y_pred[i])\n",
    "                ######################### Change this line is loss function changed\n",
    "            #             truth = torch.argmax(Y_torch_dev_cv[i])\n",
    "                truth = Y_torch_dev[i]\n",
    "                if pred == truth:\n",
    "                    correct += 1\n",
    "            acc1 = correct/len(Y_torch_dev)\n",
    "            #         acc_vals.append(acc1)\n",
    "            if loss_val < loss_val_min:\n",
    "                loss_val_min = loss_val\n",
    "                num_no_progress = 0\n",
    "            else:\n",
    "                num_no_progress += 1\n",
    "\n",
    "            if num_no_progress >= 5:\n",
    "                break\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    # Evalutate accuracy on evaluation set\n",
    "    model.eval()\n",
    "    y_pred = model(x_evaluation_set)\n",
    "    correct = 0\n",
    "    for i in range(len(y_evaluation_set)):\n",
    "        pred = torch.argmax(y_pred[i])\n",
    "        ######################### Change this line is loss function changed\n",
    "    #             truth = torch.argmax(y_evaluation_set_cv[i])\n",
    "        truth = y_evaluation_set[i]\n",
    "        if pred == truth:\n",
    "            correct += 1\n",
    "    acc1 = correct/len(y_evaluation_set)\n",
    "\n",
    "    y_pred = model(X_torch_train)\n",
    "    correct = 0\n",
    "    for i in range(len(Y_torch_train)):\n",
    "        pred = torch.argmax(y_pred[i])\n",
    "        ######################### Change this line is loss function changed\n",
    "    #             truth = torch.argmax(y_evaluation_set_cv[i])\n",
    "        truth = Y_torch_train[i]\n",
    "        if pred == truth:\n",
    "            correct += 1\n",
    "    acc2 = correct/len(Y_torch_train)\n",
    "\n",
    "    print('test accuracy is:',acc1)    \n",
    "    \n",
    "    if per_class_acc == True: # Print per class accuracies if this boolean is true\n",
    "        nb_classes = 6\n",
    "\n",
    "        confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "        with torch.no_grad():\n",
    "        #     for i, (inputs, classes) in enumerate(test_loader):\n",
    "        #     inputs = inputs.to(device)\n",
    "        #     classes = classes.to(device)\n",
    "            outputs = model(x_evaluation_set)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            for t, p in zip(y_evaluation_set.view(-1), preds.view(-1)):\n",
    "                    confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "        # Per class accuracy\n",
    "        print('per class acc:')\n",
    "        print(confusion_matrix.diag()/confusion_matrix.sum(1))\n",
    "        print('\\n\\n\\n')\n",
    "        return acc1,confusion_matrix\n",
    "    return\n",
    "\n",
    "# LR, on test set\n",
    "# train_nn_model_and_return_accuracies(X_torch_test,Y_torch_test,'LR',401,100,0,True)\n",
    "\n",
    "\n",
    "# # NN on test set\n",
    "# train_nn_model_and_return_accuracies(X_torch_test,Y_torch_test,'NN',301,100,500,True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Logistic regression models\n",
    "#### First determine optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max feats val = 500 max_df = 0.3\n",
      "Epoch 0: train loss: 1.792738437652588       val loss: 1.7926636934280396\n",
      "Epoch 50: train loss: 1.4555295705795288       val loss: 1.4967467784881592\n",
      "Epoch 100: train loss: 1.4190374612808228       val loss: 1.4679877758026123\n",
      "Epoch 150: train loss: 1.4082634449005127       val loss: 1.4589922428131104\n",
      "Epoch 200: train loss: 1.4038244485855103       val loss: 1.4551243782043457\n",
      "Epoch 250: train loss: 1.4017456769943237       val loss: 1.45331609249115\n",
      "Epoch 300: train loss: 1.400684118270874       val loss: 1.452474594116211\n",
      "Epoch 350: train loss: 1.4000965356826782       val loss: 1.4521028995513916\n",
      "Epoch 400: train loss: 1.3997650146484375       val loss: 1.4519506692886353\n",
      "test accuracy is: 0.417\n",
      "max feats val = 500 max_df = 0.5\n",
      "Epoch 0: train loss: 1.791796326637268       val loss: 1.7910701036453247\n",
      "Epoch 50: train loss: 1.4540984630584717       val loss: 1.495802402496338\n",
      "Epoch 100: train loss: 1.4165393114089966       val loss: 1.4662984609603882\n",
      "Epoch 150: train loss: 1.405236005783081       val loss: 1.4569565057754517\n",
      "Epoch 200: train loss: 1.4005528688430786       val loss: 1.4529874324798584\n",
      "Epoch 250: train loss: 1.3983519077301025       val loss: 1.4511336088180542\n",
      "Epoch 300: train loss: 1.3972162008285522       val loss: 1.4502594470977783\n",
      "Epoch 350: train loss: 1.3965898752212524       val loss: 1.4498625993728638\n",
      "Epoch 400: train loss: 1.3962453603744507       val loss: 1.4496928453445435\n",
      "test accuracy is: 0.42033333333333334\n",
      "max feats val = 500 max_df = 0.7\n",
      "Epoch 0: train loss: 1.7921611070632935       val loss: 1.7924894094467163\n",
      "Epoch 50: train loss: 1.4539976119995117       val loss: 1.4958865642547607\n",
      "Epoch 100: train loss: 1.4164416790008545       val loss: 1.4663612842559814\n",
      "Epoch 150: train loss: 1.4051977396011353       val loss: 1.4569679498672485\n",
      "Epoch 200: train loss: 1.4005420207977295       val loss: 1.453007698059082\n",
      "Epoch 250: train loss: 1.3983534574508667       val loss: 1.4511525630950928\n",
      "Epoch 300: train loss: 1.3972076177597046       val loss: 1.4502711296081543\n",
      "Epoch 350: train loss: 1.3965890407562256       val loss: 1.4498701095581055\n",
      "Epoch 400: train loss: 1.3962407112121582       val loss: 1.4496933221817017\n",
      "test accuracy is: 0.42\n",
      "max feats val = 1000 max_df = 0.3\n",
      "Epoch 0: train loss: 1.7915645837783813       val loss: 1.7913153171539307\n",
      "Epoch 50: train loss: 1.3811546564102173       val loss: 1.4543124437332153\n",
      "Epoch 100: train loss: 1.32981276512146       val loss: 1.4280940294265747\n",
      "Epoch 150: train loss: 1.3135207891464233       val loss: 1.4200496673583984\n",
      "Epoch 200: train loss: 1.3063089847564697       val loss: 1.4164721965789795\n",
      "Epoch 250: train loss: 1.3026490211486816       val loss: 1.414742350578308\n",
      "Epoch 300: train loss: 1.3006269931793213       val loss: 1.413938045501709\n",
      "Epoch 350: train loss: 1.2994496822357178       val loss: 1.4136130809783936\n",
      "test accuracy is: 0.4415\n",
      "max feats val = 1000 max_df = 0.5\n",
      "Epoch 0: train loss: 1.7917325496673584       val loss: 1.7918376922607422\n",
      "Epoch 50: train loss: 1.3798596858978271       val loss: 1.4528447389602661\n",
      "Epoch 100: train loss: 1.3278306722640991       val loss: 1.4263848066329956\n",
      "Epoch 150: train loss: 1.311134934425354       val loss: 1.4181575775146484\n",
      "Epoch 200: train loss: 1.3037126064300537       val loss: 1.4145350456237793\n",
      "Epoch 250: train loss: 1.2999211549758911       val loss: 1.4127825498580933\n",
      "Epoch 300: train loss: 1.2978324890136719       val loss: 1.4119620323181152\n",
      "Epoch 350: train loss: 1.2966217994689941       val loss: 1.4116276502609253\n",
      "test accuracy is: 0.44283333333333336\n",
      "max feats val = 1000 max_df = 0.7\n",
      "Epoch 0: train loss: 1.7922179698944092       val loss: 1.792588233947754\n",
      "Epoch 50: train loss: 1.3802777528762817       val loss: 1.4534809589385986\n",
      "Epoch 100: train loss: 1.3279660940170288       val loss: 1.426553726196289\n",
      "Epoch 150: train loss: 1.3112152814865112       val loss: 1.4182454347610474\n",
      "Epoch 200: train loss: 1.303772211074829       val loss: 1.4145841598510742\n",
      "Epoch 250: train loss: 1.2999777793884277       val loss: 1.4128133058547974\n",
      "Epoch 300: train loss: 1.2978758811950684       val loss: 1.4119774103164673\n",
      "Epoch 350: train loss: 1.2966481447219849       val loss: 1.4116370677947998\n",
      "Epoch 400: train loss: 1.2959073781967163       val loss: 1.4115480184555054\n",
      "test accuracy is: 0.44316666666666665\n",
      "max feats val = 2000 max_df = 0.3\n",
      "Epoch 0: train loss: 1.792116403579712       val loss: 1.7921761274337769\n",
      "Epoch 50: train loss: 1.3065223693847656       val loss: 1.4385336637496948\n",
      "test accuracy is: 0.43316666666666664\n",
      "max feats val = 2000 max_df = 0.5\n",
      "Epoch 0: train loss: 1.79158616065979       val loss: 1.7916250228881836\n",
      "Epoch 50: train loss: 1.3051166534423828       val loss: 1.4375239610671997\n",
      "test accuracy is: 0.432\n",
      "max feats val = 2000 max_df = 0.7\n",
      "Epoch 0: train loss: 1.7916369438171387       val loss: 1.7915886640548706\n",
      "Epoch 50: train loss: 1.3050918579101562       val loss: 1.43743896484375\n",
      "test accuracy is: 0.43283333333333335\n",
      "max feats val = 4000 max_df = 0.3\n",
      "Epoch 0: train loss: 1.791395664215088       val loss: 1.7914140224456787\n",
      "Epoch 50: train loss: 1.2106281518936157       val loss: 1.4236432313919067\n",
      "test accuracy is: 0.4325\n",
      "max feats val = 4000 max_df = 0.5\n",
      "Epoch 0: train loss: 1.7915676832199097       val loss: 1.7916984558105469\n",
      "Epoch 50: train loss: 1.210581660270691       val loss: 1.4223711490631104\n",
      "test accuracy is: 0.43316666666666664\n",
      "max feats val = 4000 max_df = 0.7\n",
      "Epoch 0: train loss: 1.7915998697280884       val loss: 1.791661262512207\n",
      "Epoch 50: train loss: 1.2104889154434204       val loss: 1.4223413467407227\n",
      "test accuracy is: 0.4325\n"
     ]
    }
   ],
   "source": [
    "# Determining the optimal hyperparameters for \"max features\" and \"max_df\" for LR by evaluating accuracies on dev set\n",
    "for max_feats in(500,1000,2000):\n",
    "    for min_occurences in(0.3,0.5,0.7):\n",
    "        print('max feats val =',max_feats, 'max_df =',min_occurences)\n",
    "        \n",
    "        # Get TFIDF features\n",
    "        X_train,X_dev,X_test = tf_idf_features(df_train_category['cleaned_text_lst'],\\\n",
    "                                               df_dev_category['cleaned_text_lst'],\\\n",
    "                                               df_test_category['cleaned_text_lst'],max_feats,min_occurences) # Getting tfid features\n",
    "        \n",
    "        # Training and dev labels\n",
    "        Y_torch_train = torch.FloatTensor(df_train_category['class'].to_numpy())\n",
    "        Y_torch_dev = torch.FloatTensor(df_dev_category['class'].to_numpy())\n",
    "        # Y_torch_dev = Y_torch_test\n",
    "\n",
    "        # Converting everything to tensors\n",
    "        X_torch_train_content = torch.FloatTensor(X_train.toarray())\n",
    "        X_torch_dev_content = torch.FloatTensor(X_dev.toarray())\n",
    "        # X_torch_dev_content = X_torch_test_content\n",
    "\n",
    "        # Extracting length of the reviews as an additional feature\n",
    "        review_length_torch_train = torch.FloatTensor(df_train_category['len_normalized'].to_numpy())\n",
    "        review_length_torch_dev = torch.FloatTensor(df_dev_category['len_normalized'].to_numpy())\n",
    "        # review_length_torch_dev = review_length_torch_test\n",
    "        \n",
    "        # Concatenating the length of the review to the TFIDF vector\n",
    "        X_torch_train = torch.cat((X_torch_train_content, review_length_torch_train.unsqueeze(1)), 1)\n",
    "        X_torch_dev = torch.cat((X_torch_dev_content, review_length_torch_dev.unsqueeze(1)), 1)\n",
    "        \n",
    "        train_nn_model_and_return_accuracies(X_torch_dev,Y_torch_dev,'LR',401,100,0,False)\n",
    "# x_evaluation_set,y_evaluation_set,model_type,num_epochs,loss_val_min,num_no_progress,per_class_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting dfidf vectors with optimal hyperparameters\n",
    "best_hyperparam_feats = 1000\n",
    "best_hyperparam_df = 0.7\n",
    "X_train,X_dev,X_test = tf_idf_features(df_train_category['cleaned_text_lst'],\\\n",
    "                                               df_dev_category['cleaned_text_lst'],\\\n",
    "                                               df_test_category['cleaned_text_lst'],best_hyperparam_feats,best_hyperparam_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting length of summaries and extracting tfidf vector\n",
    "df_train_category['len_summary'] = df_train_category['summary_cleaned'].map(lambda x:len(x))\n",
    "df_dev_category['len_summary'] = df_dev_category['summary_cleaned'].map(lambda x:len(x))\n",
    "df_test_category['len_summary'] = df_test_category['summary_cleaned'].map(lambda x:len(x))\n",
    "\n",
    "min_len_summaries = df_train_category['len_summary'].min()\n",
    "max_len_summaries = df_train_category['len_summary'].max()\n",
    "\n",
    "df_train_category['len_summary_normalized'] = (df_train_category['len_summary']-min_len_summaries)/(max_len_summaries-min_len_summaries)\n",
    "df_dev_category['len_summary_normalized'] = (df_dev_category['len_summary']-min_len_summaries)/(max_len_summaries-min_len_summaries)\n",
    "df_test_category['len_summary_normalized'] = (df_test_category['len_summary']-min_len_summaries)/(max_len_summaries-min_len_summaries)\n",
    "\n",
    "X_train_summary,X_dev_summary,X_test_summary = tf_idf_features(df_train_category['summary_cleaned'],\\\n",
    "                                               df_dev_category['summary_cleaned'],\\\n",
    "                                               df_test_category['summary_cleaned'],1000,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant tensors (features will be concatenated based on what's included in the model)\n",
    "Y_torch_train = torch.FloatTensor(df_train_category['class'].to_numpy())\n",
    "Y_torch_dev = torch.FloatTensor(df_dev_category['class'].to_numpy())\n",
    "Y_torch_test = torch.FloatTensor(df_test_category['class'].to_numpy())\n",
    "# Y_torch_dev = Y_torch_test\n",
    "\n",
    "\n",
    "X_torch_train_content = torch.FloatTensor(X_train.toarray())\n",
    "X_torch_dev_content = torch.FloatTensor(X_dev.toarray())\n",
    "X_torch_test_content = torch.FloatTensor(X_test.toarray())\n",
    "# X_torch_dev_content = X_torch_test_content\n",
    "\n",
    "X_torch_train_summary = torch.FloatTensor(X_train_summary.toarray())\n",
    "X_torch_dev_summary = torch.FloatTensor(X_dev_summary.toarray())\n",
    "X_torch_test_summary = torch.FloatTensor(X_test_summary.toarray())\n",
    "# X_torch_dev_summary = X_torch_test_summary\n",
    "\n",
    "review_length_summary_torch_train = torch.FloatTensor(df_train_category['len_summary_normalized'].to_numpy())\n",
    "review_length_summary_torch_dev = torch.FloatTensor(df_dev_category['len_summary_normalized'].to_numpy())\n",
    "review_length_summary_torch_test = torch.FloatTensor(df_test_category['len_summary_normalized'].to_numpy())\n",
    "\n",
    "X_torch_train_summary = torch.cat((X_torch_train_summary, review_length_summary_torch_train.unsqueeze(1)), 1)\n",
    "X_torch_dev_summary = torch.cat((X_torch_dev_summary, review_length_summary_torch_dev.unsqueeze(1)), 1)\n",
    "X_torch_test_summary = torch.cat((X_torch_test_summary, review_length_summary_torch_test.unsqueeze(1)), 1)\n",
    "\n",
    "\n",
    "review_length_torch_train = torch.FloatTensor(df_train_category['len_normalized'].to_numpy())\n",
    "review_length_torch_dev = torch.FloatTensor(df_dev_category['len_normalized'].to_numpy())\n",
    "review_length_torch_test = torch.FloatTensor(df_test_category['len_normalized'].to_numpy())\n",
    "# review_length_torch_dev = review_length_torch_test\n",
    "\n",
    "year_train = torch.FloatTensor(df_train_category['review_year_normalized'].to_numpy())\n",
    "year_dev = torch.FloatTensor(df_dev_category['review_year_normalized'].to_numpy())\n",
    "year_test = torch.FloatTensor(df_test_category['review_year_normalized'].to_numpy())\n",
    "# year_dev = year_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the features used by the model and concatenating the relevant ones\n",
    "def included_feats(included_str):\n",
    "    if included_str == 'All features':\n",
    "        X_torch_train = torch.cat((X_torch_train_content, review_length_torch_train.unsqueeze(1)), 1)\n",
    "        X_torch_dev = torch.cat((X_torch_dev_content, review_length_torch_dev.unsqueeze(1)), 1)\n",
    "        X_torch_test = torch.cat((X_torch_test_content, review_length_torch_test.unsqueeze(1)), 1)\n",
    "\n",
    "        X_torch_train = torch.cat((X_torch_train, year_train.unsqueeze(1)), 1)\n",
    "        X_torch_dev = torch.cat((X_torch_dev, year_dev.unsqueeze(1)), 1)\n",
    "        X_torch_test = torch.cat((X_torch_test, year_test.unsqueeze(1)), 1)\n",
    "\n",
    "        X_torch_train = torch.cat((X_torch_train, X_torch_train_summary), 1)\n",
    "        X_torch_dev = torch.cat((X_torch_dev, X_torch_dev_summary), 1)\n",
    "        X_torch_test = torch.cat((X_torch_test, X_torch_test_summary), 1)\n",
    "\n",
    "    elif included_str == 'Non content only':\n",
    "        # Summary of review, and the year\n",
    "        X_torch_train = torch.cat((X_torch_train_summary, year_train.unsqueeze(1)), 1)\n",
    "        X_torch_dev = torch.cat((X_torch_dev_summary, year_dev.unsqueeze(1)), 1)\n",
    "        X_torch_test = torch.cat((X_torch_test_summary, year_test.unsqueeze(1)), 1)\n",
    "\n",
    "    elif included_str == 'Content only':\n",
    "        # Features that have to do with the content of the review only (the review embedding, as well as the review length)\n",
    "        X_torch_train = torch.cat((X_torch_train_content, review_length_torch_train.unsqueeze(1)), 1)\n",
    "        X_torch_dev = torch.cat((X_torch_dev_content, review_length_torch_dev.unsqueeze(1)), 1)\n",
    "        X_torch_test = torch.cat((X_torch_test_content, review_length_torch_test.unsqueeze(1)), 1)\n",
    "\n",
    "    elif included_str == 'Content and summary':\n",
    "        # Features that have to do with the content of the review only (the review embedding, as well as the review length)\n",
    "        X_torch_train = torch.cat((X_torch_train_content, review_length_torch_train.unsqueeze(1)), 1)\n",
    "        X_torch_dev = torch.cat((X_torch_dev_content, review_length_torch_dev.unsqueeze(1)), 1)\n",
    "        X_torch_test = torch.cat((X_torch_test_content, review_length_torch_test.unsqueeze(1)), 1)\n",
    "\n",
    "        X_torch_train = torch.cat((X_torch_train, X_torch_train_summary), 1)\n",
    "        X_torch_dev = torch.cat((X_torch_dev, X_torch_dev_summary), 1)\n",
    "        X_torch_test = torch.cat((X_torch_test, X_torch_test_summary), 1)\n",
    "\n",
    "    elif included_str == 'Content and year':\n",
    "        # Features that have to do with the content of the review only (the review embedding, as well as the review length)\n",
    "        X_torch_train = torch.cat((X_torch_train_content, review_length_torch_train.unsqueeze(1)), 1)\n",
    "        X_torch_dev = torch.cat((X_torch_dev_content, review_length_torch_dev.unsqueeze(1)), 1)\n",
    "        X_torch_test = torch.cat((X_torch_test_content, review_length_torch_test.unsqueeze(1)), 1)\n",
    "\n",
    "        X_torch_train = torch.cat((X_torch_train, year_train.unsqueeze(1)), 1)\n",
    "        X_torch_dev = torch.cat((X_torch_dev, year_dev.unsqueeze(1)), 1)\n",
    "        X_torch_test = torch.cat((X_torch_test, year_test.unsqueeze(1)), 1)\n",
    "    else:\n",
    "        print('Invalid Input String')\n",
    "        return -1\n",
    "        \n",
    "    return X_torch_train,X_torch_dev,X_torch_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([42000])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_length_torch_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Logistic regression model using the various combinations of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------- Content only -----------------------\n",
      "\n",
      "Epoch 0: train loss: 1.7917453050613403       val loss: 1.7916069030761719\n",
      "Epoch 50: train loss: 1.3798258304595947       val loss: 1.4528212547302246\n",
      "Epoch 100: train loss: 1.3278073072433472       val loss: 1.4263564348220825\n",
      "Epoch 150: train loss: 1.311108112335205       val loss: 1.4181230068206787\n",
      "Epoch 200: train loss: 1.3036954402923584       val loss: 1.4145101308822632\n",
      "Epoch 250: train loss: 1.2999207973480225       val loss: 1.412767767906189\n",
      "Epoch 300: train loss: 1.2978312969207764       val loss: 1.4119467735290527\n",
      "Epoch 350: train loss: 1.2966251373291016       val loss: 1.4116170406341553\n",
      "Epoch 400: train loss: 1.295884609222412       val loss: 1.4115376472473145\n",
      "test accuracy is: 0.429\n",
      "per class acc:\n",
      "tensor([0.4830, 0.4590, 0.3140, 0.3760, 0.4360, 0.5060])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----------------------- Non content only -----------------------\n",
      "\n",
      "Epoch 0: train loss: 1.79207181930542       val loss: 1.7920410633087158\n",
      "Epoch 50: train loss: 1.5388309955596924       val loss: 1.6278232336044312\n",
      "test accuracy is: 0.327\n",
      "per class acc:\n",
      "tensor([0.4570, 0.3430, 0.2910, 0.2300, 0.2760, 0.3650])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----------------------- Content and summary -----------------------\n",
      "\n",
      "Epoch 0: train loss: 1.7922580242156982       val loss: 1.791835069656372\n",
      "Epoch 50: train loss: 1.247144103050232       val loss: 1.4082542657852173\n",
      "test accuracy is: 0.43766666666666665\n",
      "per class acc:\n",
      "tensor([0.5020, 0.4740, 0.3240, 0.3560, 0.4620, 0.5080])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----------------------- Content and year -----------------------\n",
      "\n",
      "Epoch 0: train loss: 1.7910511493682861       val loss: 1.7908101081848145\n",
      "Epoch 50: train loss: 1.376924991607666       val loss: 1.4496068954467773\n",
      "Epoch 100: train loss: 1.3249235153198242       val loss: 1.4234671592712402\n",
      "Epoch 150: train loss: 1.3082342147827148       val loss: 1.4154671430587769\n",
      "Epoch 200: train loss: 1.3008410930633545       val loss: 1.4119391441345215\n",
      "Epoch 250: train loss: 1.2970666885375977       val loss: 1.4102452993392944\n",
      "Epoch 300: train loss: 1.294978380203247       val loss: 1.4094600677490234\n",
      "Epoch 350: train loss: 1.2937716245651245       val loss: 1.409160852432251\n",
      "test accuracy is: 0.4335\n",
      "per class acc:\n",
      "tensor([0.4990, 0.4630, 0.3100, 0.3780, 0.4410, 0.5100])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----------------------- All features -----------------------\n",
      "\n",
      "Epoch 0: train loss: 1.7918431758880615       val loss: 1.7915074825286865\n",
      "Epoch 50: train loss: 1.2442066669464111       val loss: 1.4046696424484253\n",
      "test accuracy is: 0.44\n",
      "per class acc:\n",
      "tensor([0.5030, 0.4770, 0.3270, 0.3580, 0.4640, 0.5110])\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combinations of features to try\n",
    "included_strings = ['Content only','Non content only','Content and summary','Content and year','All features']\n",
    "\n",
    "# Store accuracies and confusion matrices\n",
    "accs_lr = dict()\n",
    "conf_mat_lr = dict()\n",
    "\n",
    "for included_str in included_strings:\n",
    "    X_torch_train,X_torch_dev,X_torch_test = included_feats(included_str)\n",
    "    print('-----------------------',included_str,'-----------------------\\n')\n",
    "    acc,cm = train_nn_model_and_return_accuracies(X_torch_test,Y_torch_test,'LR',401,100,0,True)\n",
    "    accs_lr[included_str] = acc\n",
    "    conf_mat_lr[included_str] = cm/1000.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Content only': 0.000429,\n",
       " 'Non content only': 0.00032700000000000003,\n",
       " 'Content and summary': 0.00043766666666666666,\n",
       " 'Content and year': 0.0004335,\n",
       " 'All features': 0.00044}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Content only': tensor([[483., 177., 135.,  61., 116.,  28.],\n",
       "         [201., 459.,  85., 154.,  58.,  43.],\n",
       "         [196.,  89., 314., 135., 165., 101.],\n",
       "         [ 50., 146., 172., 376.,  72., 184.],\n",
       "         [ 91.,  71., 117.,  77., 436., 208.],\n",
       "         [ 35.,  42.,  64., 144., 209., 506.]]),\n",
       " 'Non content only': tensor([[457., 155., 161.,  75.,  94.,  58.],\n",
       "         [269., 343., 136., 104.,  79.,  69.],\n",
       "         [211.,  94., 291., 149., 124., 131.],\n",
       "         [125., 150., 203., 230., 118., 174.],\n",
       "         [165.,  82., 176.,  84., 276., 217.],\n",
       "         [113.,  67., 140., 121., 194., 365.]]),\n",
       " 'Content and summary': tensor([[502., 166., 155.,  61.,  86.,  30.],\n",
       "         [211., 474.,  89., 122.,  59.,  45.],\n",
       "         [184.,  85., 324., 160., 162.,  85.],\n",
       "         [ 49., 134., 197., 356.,  82., 182.],\n",
       "         [ 91.,  58., 119.,  85., 462., 185.],\n",
       "         [ 31.,  34.,  79., 132., 216., 508.]]),\n",
       " 'Content and year': tensor([[499., 174., 131.,  57., 110.,  29.],\n",
       "         [198., 463.,  88., 152.,  61.,  38.],\n",
       "         [194.,  93., 310., 136., 164., 103.],\n",
       "         [ 48., 144., 171., 378.,  76., 183.],\n",
       "         [ 90.,  73., 116.,  79., 441., 201.],\n",
       "         [ 34.,  38.,  68., 145., 205., 510.]]),\n",
       " 'All features': tensor([[503., 173., 154.,  57.,  86.,  27.],\n",
       "         [205., 477.,  93., 119.,  60.,  46.],\n",
       "         [182.,  84., 327., 167., 157.,  83.],\n",
       "         [ 55., 132., 193., 358.,  84., 178.],\n",
       "         [ 92.,  60., 120.,  84., 464., 180.],\n",
       "         [ 23.,  31.,  81., 133., 221., 511.]])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(conf_mat_lr)\n",
    "accs_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving accuracies and confusion matrices for all models to compare later in the analysis\n",
    "accs_all_classifiers['lr'] = accs_lr\n",
    "conf_mats_all_classifiers['lr'] = conf_mat_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training 1-hidden layer NN models\n",
    "#### First determine optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max feats val = 500 max_df = 0.3\n",
      "Epoch 0: train loss: 1.7918574810028076       val loss: 1.7917752265930176\n",
      "test accuracy is: 0.4\n",
      "max feats val = 500 max_df = 0.5\n",
      "Epoch 0: train loss: 1.7917269468307495       val loss: 1.7917548418045044\n",
      "test accuracy is: 0.4048333333333333\n",
      "max feats val = 500 max_df = 0.7\n",
      "Epoch 0: train loss: 1.791793704032898       val loss: 1.791735053062439\n",
      "test accuracy is: 0.406\n",
      "max feats val = 1000 max_df = 0.3\n",
      "Epoch 0: train loss: 1.7916555404663086       val loss: 1.7917845249176025\n",
      "test accuracy is: 0.4266666666666667\n",
      "max feats val = 1000 max_df = 0.5\n",
      "Epoch 0: train loss: 1.791955590248108       val loss: 1.7918492555618286\n",
      "test accuracy is: 0.42533333333333334\n",
      "max feats val = 1000 max_df = 0.7\n",
      "Epoch 0: train loss: 1.791745901107788       val loss: 1.7917332649230957\n",
      "test accuracy is: 0.42483333333333334\n",
      "max feats val = 2000 max_df = 0.3\n",
      "Epoch 0: train loss: 1.791524052619934       val loss: 1.7917063236236572\n",
      "test accuracy is: 0.43433333333333335\n",
      "max feats val = 2000 max_df = 0.5\n",
      "Epoch 0: train loss: 1.791612148284912       val loss: 1.7917307615280151\n",
      "test accuracy is: 0.42983333333333335\n",
      "max feats val = 2000 max_df = 0.7\n",
      "Epoch 0: train loss: 1.7918002605438232       val loss: 1.7917327880859375\n",
      "test accuracy is: 0.43116666666666664\n"
     ]
    }
   ],
   "source": [
    "# Determining the optimal hyperparameters for \"max features\" and \"max_df\" for LR by evaluating accuracies on dev set\n",
    "for max_feats in(500,1000,2000):\n",
    "    for min_occurences in(0.3,0.5,0.7):\n",
    "        print('max feats val =',max_feats, 'max_df =',min_occurences)\n",
    "        \n",
    "        # Get TFIDF features\n",
    "        X_train,X_dev,X_test = tf_idf_features(df_train_category['cleaned_text_lst'],\\\n",
    "                                               df_dev_category['cleaned_text_lst'],\\\n",
    "                                               df_test_category['cleaned_text_lst'],max_feats,min_occurences) # Getting tfid features\n",
    "        \n",
    "        # Training and dev labels\n",
    "        Y_torch_train = torch.FloatTensor(df_train_category['class'].to_numpy())\n",
    "        Y_torch_dev = torch.FloatTensor(df_dev_category['class'].to_numpy())\n",
    "        # Y_torch_dev = Y_torch_test\n",
    "\n",
    "        # Converting everything to tensors\n",
    "        X_torch_train_content = torch.FloatTensor(X_train.toarray())\n",
    "        X_torch_dev_content = torch.FloatTensor(X_dev.toarray())\n",
    "        # X_torch_dev_content = X_torch_test_content\n",
    "\n",
    "        # Extracting length of the reviews as an additional feature\n",
    "        review_length_torch_train = torch.FloatTensor(df_train_category['len_normalized'].to_numpy())\n",
    "        review_length_torch_dev = torch.FloatTensor(df_dev_category['len_normalized'].to_numpy())\n",
    "        # review_length_torch_dev = review_length_torch_test\n",
    "        \n",
    "        # Concatenating the length of the review to the TFIDF vector\n",
    "        X_torch_train = torch.cat((X_torch_train_content, review_length_torch_train.unsqueeze(1)), 1)\n",
    "        X_torch_dev = torch.cat((X_torch_dev_content, review_length_torch_dev.unsqueeze(1)), 1)\n",
    "        \n",
    "        train_nn_model_and_return_accuracies(X_torch_dev,Y_torch_dev,'NN',301,100,500,False)\n",
    "# x_evaluation_set,y_evaluation_set,model_type,num_epochs,loss_val_min,num_no_progress,per_class_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting dfidf vectors with optimal hyperparameters\n",
    "best_hyperparam_feats = 1000\n",
    "best_hyperparam_df = 0.7\n",
    "X_train,X_dev,X_test = tf_idf_features(df_train_category['cleaned_text_lst'],\\\n",
    "                                               df_dev_category['cleaned_text_lst'],\\\n",
    "                                               df_test_category['cleaned_text_lst'],best_hyperparam_feats,best_hyperparam_df)\n",
    "# Converting training data to tensors\n",
    "X_torch_train_content = torch.FloatTensor(X_train.toarray())\n",
    "X_torch_dev_content = torch.FloatTensor(X_dev.toarray())\n",
    "X_torch_test_content = torch.FloatTensor(X_test.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the the Neural network using the various combinations of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------- Content only -----------------------\n",
      "\n",
      "Epoch 0: train loss: 1.7917693853378296       val loss: 1.7917897701263428\n",
      "test accuracy is: 0.41983333333333334\n",
      "per class acc:\n",
      "tensor([0.4760, 0.4670, 0.2950, 0.3690, 0.4210, 0.4910])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----------------------- Non content only -----------------------\n",
      "\n",
      "Epoch 0: train loss: 1.7918318510055542       val loss: 1.7917348146438599\n",
      "test accuracy is: 0.323\n",
      "per class acc:\n",
      "tensor([0.4180, 0.3440, 0.2610, 0.2450, 0.3090, 0.3610])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----------------------- Content and summary -----------------------\n",
      "\n",
      "Epoch 0: train loss: 1.7919135093688965       val loss: 1.7917280197143555\n",
      "test accuracy is: 0.43266666666666664\n",
      "per class acc:\n",
      "tensor([0.5260, 0.4480, 0.3230, 0.3610, 0.4020, 0.5360])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----------------------- Content and year -----------------------\n",
      "\n",
      "Epoch 0: train loss: 1.7916138172149658       val loss: 1.7917559146881104\n",
      "test accuracy is: 0.418\n",
      "per class acc:\n",
      "tensor([0.4740, 0.4650, 0.2910, 0.3710, 0.3930, 0.5140])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----------------------- All features -----------------------\n",
      "\n",
      "Epoch 0: train loss: 1.7919198274612427       val loss: 1.7917828559875488\n",
      "test accuracy is: 0.43816666666666665\n",
      "per class acc:\n",
      "tensor([0.5100, 0.4810, 0.3350, 0.3460, 0.3940, 0.5630])\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combinations of features to try\n",
    "included_strings = ['Content only','Non content only','Content and summary','Content and year','All features']\n",
    "\n",
    "# Store accuracies and confusion matrices\n",
    "accs_NN = dict()\n",
    "conf_mat_NN = dict()\n",
    "\n",
    "for included_str in included_strings:\n",
    "    X_torch_train,X_torch_dev,X_torch_test = included_feats(included_str)\n",
    "    print('-----------------------',included_str,'-----------------------\\n')\n",
    "    acc,cm = train_nn_model_and_return_accuracies(X_torch_test,Y_torch_test,'NN',301,100,500,True)\n",
    "    accs_NN[included_str] = acc\n",
    "    conf_mat_NN[included_str] = cm/1000.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------- Content only -----------------------\n",
      "\n",
      "Epoch 0: train loss: 1.7920063734054565       val loss: 1.7917832136154175\n",
      "Epoch 10: train loss: 1.6427983045578003       val loss: 1.679885745048523\n",
      "test accuracy is: 0.4185\n",
      "Per Class Accuracy:\n",
      "tensor([0.4790, 0.4970, 0.3230, 0.3160, 0.4060, 0.4900])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----------------------- Non content only -----------------------\n",
      "\n",
      "Epoch 0: train loss: 1.7916207313537598       val loss: 1.7917343378067017\n",
      "Epoch 10: train loss: 1.6949483156204224       val loss: 1.7261940240859985\n",
      "test accuracy is: 0.3055\n",
      "Per Class Accuracy:\n",
      "tensor([0.4790, 0.3530, 0.2030, 0.1900, 0.2730, 0.3350])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----------------------- Content and summary -----------------------\n",
      "\n",
      "Epoch 0: train loss: 1.7917296886444092       val loss: 1.7917546033859253\n",
      "Epoch 10: train loss: 1.6170746088027954       val loss: 1.6740939617156982\n",
      "test accuracy is: 0.44083333333333335\n",
      "Per Class Accuracy:\n",
      "tensor([0.5080, 0.4930, 0.3080, 0.3740, 0.4390, 0.5230])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----------------------- Content and year -----------------------\n",
      "\n",
      "Epoch 0: train loss: 1.7919038534164429       val loss: 1.7918250560760498\n",
      "Epoch 10: train loss: 1.6436316967010498       val loss: 1.680150032043457\n",
      "test accuracy is: 0.4235\n",
      "Per Class Accuracy:\n",
      "tensor([0.5190, 0.5060, 0.2830, 0.3240, 0.4230, 0.4860])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----------------------- All features -----------------------\n",
      "\n",
      "Epoch 0: train loss: 1.792065978050232       val loss: 1.7918336391448975\n",
      "Epoch 10: train loss: 1.6153898239135742       val loss: 1.6724318265914917\n",
      "test accuracy is: 0.43866666666666665\n",
      "Per Class Accuracy:\n",
      "tensor([0.5250, 0.4800, 0.3230, 0.3250, 0.4340, 0.5450])\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    " # Creating Neural Network with 1 hidden layer\n",
    "\n",
    "accs_NN = dict()\n",
    "conf_mat_NN = dict()\n",
    "for included_str in included_strings:\n",
    "    X_torch_train,X_torch_dev,X_torch_test = included_feats(included_str)\n",
    "    print('-----------------------',included_str,'-----------------------\\n')    \n",
    "\n",
    "    input_dim = X_torch_train.shape[1]\n",
    "    model = Feed_Forward_Neural_Net(input_dim,500)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.02)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "\n",
    "\n",
    "    # Training the model\n",
    "    model.train()\n",
    "    epoch = 301\n",
    "    loss_val_min = 100\n",
    "    num_no_progress = 500\n",
    "    for epoch in range(epoch):\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        y_pred = model(X_torch_train)\n",
    "    #         print(y_pred.shape)\n",
    "        # Compute Loss\n",
    "    #     print(min(y_pred))\n",
    "    #         print(y_pred[1])\n",
    "        loss = criterion(y_pred.squeeze().float(), Y_torch_train.long())\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(X_torch_dev)\n",
    "            correct = 0\n",
    "            loss_val = criterion(y_pred.squeeze().float(), Y_torch_dev.long())\n",
    "            if epoch % 10 == 0:\n",
    "                print('Epoch {}: train loss: {}       val loss: {}'.format(epoch, loss.item(),loss_val.item()))\n",
    "            for i in range(len(Y_torch_dev)):\n",
    "                pred = torch.argmax(y_pred[i])\n",
    "                ######################### Change this line is loss function changed\n",
    "            #             truth = torch.argmax(Y_torch_test_cv[i])\n",
    "                truth = Y_torch_dev[i]\n",
    "                if pred == truth:\n",
    "                    correct += 1\n",
    "            acc1 = correct/len(Y_torch_dev)\n",
    "            #         acc_vals.append(acc1)\n",
    "            if loss_val < loss_val_min:\n",
    "                loss_val_min = loss_val\n",
    "                num_no_progress = 0\n",
    "            else:\n",
    "                num_no_progress += 1\n",
    "\n",
    "            if num_no_progress >= 5:\n",
    "                break\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    # Evalutate accuracy on test set\n",
    "    model.eval()\n",
    "    y_pred = model(X_torch_test)\n",
    "    correct = 0\n",
    "    for i in range(len(Y_torch_test)):\n",
    "        pred = torch.argmax(y_pred[i])\n",
    "        ######################### Change this line is loss function changed\n",
    "    #             truth = torch.argmax(Y_torch_test_cv[i])\n",
    "        truth = Y_torch_test[i]\n",
    "        if pred == truth:\n",
    "            correct += 1\n",
    "    acc1 = correct/len(Y_torch_test)\n",
    "\n",
    "    y_pred = model(X_torch_train)\n",
    "    correct = 0\n",
    "    for i in range(len(Y_torch_train)):\n",
    "        pred = torch.argmax(y_pred[i])\n",
    "        ######################### Change this line is loss function changed\n",
    "    #             truth = torch.argmax(Y_torch_test_cv[i])\n",
    "        truth = Y_torch_train[i]\n",
    "        if pred == truth:\n",
    "            correct += 1\n",
    "    acc2 = correct/len(Y_torch_train)\n",
    "\n",
    "    accs_NN[included_str] = acc1\n",
    "\n",
    "    \n",
    "    print('test accuracy is:',acc1)\n",
    "    \n",
    "    nb_classes = 6\n",
    "\n",
    "    confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "    with torch.no_grad():\n",
    "    #     for i, (inputs, classes) in enumerate(test_loader):\n",
    "    #     inputs = inputs.to(device)\n",
    "    #     classes = classes.to(device)\n",
    "        outputs = model(X_torch_test)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for t, p in zip(Y_torch_test.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "    conf_mat_NN[included_str] = confusion_matrix/1000\n",
    "    # Per class accuracy\n",
    "    print('Per Class Accuracy:')\n",
    "    print(confusion_matrix.diag()/confusion_matrix.sum(1))\n",
    "    print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving accuracies and confusion matrices for later analysis\n",
    "accs_all_classifiers['nn'] = accs_NN\n",
    "conf_mats_all_classifiers['nn'] = conf_mat_NN\n",
    "\n",
    "review_by_category_accs['Moviestv'] = accs_all_classifiers\n",
    "review_by_category_confusion_matrix['Moviestv'] = conf_mats_all_classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Moviestv': {'nn': {'Content only': tensor([[476., 172., 143.,  72.,  98.,  39.],\n",
       "           [184., 467., 103., 133.,  63.,  50.],\n",
       "           [194., 101., 295., 152., 154., 104.],\n",
       "           [ 55., 150., 175., 369.,  76., 175.],\n",
       "           [ 92.,  85., 113.,  95., 421., 194.],\n",
       "           [ 38.,  48.,  70., 154., 199., 491.]]),\n",
       "   'Non content only': tensor([[418., 159., 156.,  72., 122.,  73.],\n",
       "           [258., 344., 119., 113.,  94.,  72.],\n",
       "           [182.,  94., 261., 161., 158., 144.],\n",
       "           [123., 143., 192., 245., 122., 175.],\n",
       "           [130.,  74., 145., 114., 309., 228.],\n",
       "           [ 93.,  60., 128., 141., 217., 361.]]),\n",
       "   'Content and summary': tensor([[526., 156., 138.,  67.,  76.,  37.],\n",
       "           [220., 448., 101., 131.,  47.,  53.],\n",
       "           [187.,  81., 323., 178., 135.,  96.],\n",
       "           [ 51., 128., 193., 361.,  78., 189.],\n",
       "           [ 93.,  52., 118.,  89., 402., 246.],\n",
       "           [ 32.,  35.,  76., 142., 179., 536.]]),\n",
       "   'Content and year': tensor([[474., 180., 146.,  68.,  93.,  39.],\n",
       "           [184., 465., 104., 130.,  63.,  54.],\n",
       "           [182., 104., 291., 157., 146., 120.],\n",
       "           [ 44., 152., 169., 371.,  65., 199.],\n",
       "           [ 94.,  83., 126.,  88., 393., 216.],\n",
       "           [ 41.,  46.,  70., 164., 165., 514.]]),\n",
       "   'All features': tensor([[510., 170., 145.,  63.,  80.,  32.],\n",
       "           [200., 481.,  96., 126.,  37.,  60.],\n",
       "           [178.,  90., 335., 161., 127., 109.],\n",
       "           [ 44., 142., 200., 346.,  69., 199.],\n",
       "           [ 89.,  55., 131.,  85., 394., 246.],\n",
       "           [ 29.,  34.,  68., 136., 170., 563.]])},\n",
       "  'lr': {'Content only': tensor([[483., 177., 135.,  61., 116.,  28.],\n",
       "           [201., 459.,  85., 154.,  58.,  43.],\n",
       "           [196.,  89., 314., 135., 165., 101.],\n",
       "           [ 50., 146., 172., 376.,  72., 184.],\n",
       "           [ 91.,  71., 117.,  77., 436., 208.],\n",
       "           [ 35.,  42.,  64., 144., 209., 506.]]),\n",
       "   'Non content only': tensor([[457., 155., 161.,  75.,  94.,  58.],\n",
       "           [269., 343., 136., 104.,  79.,  69.],\n",
       "           [211.,  94., 291., 149., 124., 131.],\n",
       "           [125., 150., 203., 230., 118., 174.],\n",
       "           [165.,  82., 176.,  84., 276., 217.],\n",
       "           [113.,  67., 140., 121., 194., 365.]]),\n",
       "   'Content and summary': tensor([[502., 166., 155.,  61.,  86.,  30.],\n",
       "           [211., 474.,  89., 122.,  59.,  45.],\n",
       "           [184.,  85., 324., 160., 162.,  85.],\n",
       "           [ 49., 134., 197., 356.,  82., 182.],\n",
       "           [ 91.,  58., 119.,  85., 462., 185.],\n",
       "           [ 31.,  34.,  79., 132., 216., 508.]]),\n",
       "   'Content and year': tensor([[499., 174., 131.,  57., 110.,  29.],\n",
       "           [198., 463.,  88., 152.,  61.,  38.],\n",
       "           [194.,  93., 310., 136., 164., 103.],\n",
       "           [ 48., 144., 171., 378.,  76., 183.],\n",
       "           [ 90.,  73., 116.,  79., 441., 201.],\n",
       "           [ 34.,  38.,  68., 145., 205., 510.]]),\n",
       "   'All features': tensor([[503., 173., 154.,  57.,  86.,  27.],\n",
       "           [205., 477.,  93., 119.,  60.,  46.],\n",
       "           [182.,  84., 327., 167., 157.,  83.],\n",
       "           [ 55., 132., 193., 358.,  84., 178.],\n",
       "           [ 92.,  60., 120.,  84., 464., 180.],\n",
       "           [ 23.,  31.,  81., 133., 221., 511.]])}}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_by_category_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Training_Models import train_all_models_and_return_results\n",
    "accs_all_classifiers,conf_mats_all_classifiers = train_all_models_and_return_results()\n",
    "\n",
    "review_by_category_accs['Books'] = accs_all_classifiers\n",
    "review_by_category_confusion_matrix['Books'] = conf_mats_all_classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_by_category_accs['Books'] = accs_all_classifiers\n",
    "review_by_category_confusion_matrix['Books'] = conf_mats_all_classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Moviestv': {'nn': {'Content only': tensor([[476., 172., 143.,  72.,  98.,  39.],\n",
       "           [184., 467., 103., 133.,  63.,  50.],\n",
       "           [194., 101., 295., 152., 154., 104.],\n",
       "           [ 55., 150., 175., 369.,  76., 175.],\n",
       "           [ 92.,  85., 113.,  95., 421., 194.],\n",
       "           [ 38.,  48.,  70., 154., 199., 491.]]),\n",
       "   'Non content only': tensor([[418., 159., 156.,  72., 122.,  73.],\n",
       "           [258., 344., 119., 113.,  94.,  72.],\n",
       "           [182.,  94., 261., 161., 158., 144.],\n",
       "           [123., 143., 192., 245., 122., 175.],\n",
       "           [130.,  74., 145., 114., 309., 228.],\n",
       "           [ 93.,  60., 128., 141., 217., 361.]]),\n",
       "   'Content and summary': tensor([[526., 156., 138.,  67.,  76.,  37.],\n",
       "           [220., 448., 101., 131.,  47.,  53.],\n",
       "           [187.,  81., 323., 178., 135.,  96.],\n",
       "           [ 51., 128., 193., 361.,  78., 189.],\n",
       "           [ 93.,  52., 118.,  89., 402., 246.],\n",
       "           [ 32.,  35.,  76., 142., 179., 536.]]),\n",
       "   'Content and year': tensor([[474., 180., 146.,  68.,  93.,  39.],\n",
       "           [184., 465., 104., 130.,  63.,  54.],\n",
       "           [182., 104., 291., 157., 146., 120.],\n",
       "           [ 44., 152., 169., 371.,  65., 199.],\n",
       "           [ 94.,  83., 126.,  88., 393., 216.],\n",
       "           [ 41.,  46.,  70., 164., 165., 514.]]),\n",
       "   'All features': tensor([[510., 170., 145.,  63.,  80.,  32.],\n",
       "           [200., 481.,  96., 126.,  37.,  60.],\n",
       "           [178.,  90., 335., 161., 127., 109.],\n",
       "           [ 44., 142., 200., 346.,  69., 199.],\n",
       "           [ 89.,  55., 131.,  85., 394., 246.],\n",
       "           [ 29.,  34.,  68., 136., 170., 563.]])},\n",
       "  'lr': {'Content only': tensor([[483., 177., 135.,  61., 116.,  28.],\n",
       "           [201., 459.,  85., 154.,  58.,  43.],\n",
       "           [196.,  89., 314., 135., 165., 101.],\n",
       "           [ 50., 146., 172., 376.,  72., 184.],\n",
       "           [ 91.,  71., 117.,  77., 436., 208.],\n",
       "           [ 35.,  42.,  64., 144., 209., 506.]]),\n",
       "   'Non content only': tensor([[457., 155., 161.,  75.,  94.,  58.],\n",
       "           [269., 343., 136., 104.,  79.,  69.],\n",
       "           [211.,  94., 291., 149., 124., 131.],\n",
       "           [125., 150., 203., 230., 118., 174.],\n",
       "           [165.,  82., 176.,  84., 276., 217.],\n",
       "           [113.,  67., 140., 121., 194., 365.]]),\n",
       "   'Content and summary': tensor([[502., 166., 155.,  61.,  86.,  30.],\n",
       "           [211., 474.,  89., 122.,  59.,  45.],\n",
       "           [184.,  85., 324., 160., 162.,  85.],\n",
       "           [ 49., 134., 197., 356.,  82., 182.],\n",
       "           [ 91.,  58., 119.,  85., 462., 185.],\n",
       "           [ 31.,  34.,  79., 132., 216., 508.]]),\n",
       "   'Content and year': tensor([[499., 174., 131.,  57., 110.,  29.],\n",
       "           [198., 463.,  88., 152.,  61.,  38.],\n",
       "           [194.,  93., 310., 136., 164., 103.],\n",
       "           [ 48., 144., 171., 378.,  76., 183.],\n",
       "           [ 90.,  73., 116.,  79., 441., 201.],\n",
       "           [ 34.,  38.,  68., 145., 205., 510.]]),\n",
       "   'All features': tensor([[503., 173., 154.,  57.,  86.,  27.],\n",
       "           [205., 477.,  93., 119.,  60.,  46.],\n",
       "           [182.,  84., 327., 167., 157.,  83.],\n",
       "           [ 55., 132., 193., 358.,  84., 178.],\n",
       "           [ 92.,  60., 120.,  84., 464., 180.],\n",
       "           [ 23.,  31.,  81., 133., 221., 511.]])}},\n",
       " 'Books': {'nb': {'Content Alone': 0.4145,\n",
       "   'Non Content': 0.3515,\n",
       "   'Content and Summary': 0.43083333333333335,\n",
       "   'Content and Year': 0.41333333333333333,\n",
       "   'All Features': 0.434},\n",
       "  'lr': {'Content only': 0.429,\n",
       "   'Non content only': 0.3275,\n",
       "   'Content and summary': 0.43633333333333335,\n",
       "   'Content and year': 0.433,\n",
       "   'All features': 0.44066666666666665},\n",
       "  'nn': {'Content only': 0.41333333333333333,\n",
       "   'Non content only': 0.3235,\n",
       "   'Content and summary': 0.43416666666666665,\n",
       "   'Content and year': 0.4181666666666667,\n",
       "   'All features': 0.43683333333333335}}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_by_category_accs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
